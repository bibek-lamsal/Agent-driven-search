{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "05b07531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Annotated\n",
    "import operator\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "1afd0df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    topic: str\n",
    "    search_queries : Annotated[List[str], operator.add]\n",
    "    context: Annotated[List[str], operator.add]\n",
    "    summary: str\n",
    "    critique: str\n",
    "    iterations: Annotated[int, operator.add]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "c098a622",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "import os\n",
    "\n",
    "# Initialize the client (ensure GOOGLE_API_KEY is in your env)\n",
    "# google_client = genai.Client(api_key=\"************************\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"*************************\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "92047fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tavily import TavilyClient\n",
    "client = TavilyClient(\"tvly-dev-***********************\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "0bdfb127",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "f808ede7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_queries_node(state: AgentState):\n",
    "    topic = state[\"topic\"]\n",
    "    # Prompt the LLM to generate 3 specific search queries\n",
    "    prompt = f\"Give me 3 search queries to research the following topic: {topic}. Return them as comma separated list example output: A,B,C. Make sure there is no comma used other than used to separate search queries.\"\n",
    "    \n",
    "    # Let's say the LLM returns: [\"agentic ai architecture\", \"langgraph vs autogen\", \"agentic design patterns\"]\n",
    "    new_queries = llm.invoke(prompt) \n",
    "    cleaned_queries = new_queries.content.split(\",\")\n",
    "    # Return the new list. LangGraph will merge this into the state's 'search_queries'\n",
    "    return {\"search_queries\": cleaned_queries}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "5fe40c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_node(state: AgentState): \n",
    "    current_iter = state[\"iterations\"]\n",
    "    latest_query = state[\"search_queries\"][current_iter]\n",
    "    cleaned_result = []\n",
    "    response = client.search(\n",
    "    query = latest_query, max_results=3\n",
    ")\n",
    "#     state[\"search_queries\"] = f\"latest info on {topic}\"\n",
    "    for item in response['results']:\n",
    "        content = item.get('content')\n",
    "        url = item.get('url')\n",
    "        cleaned_result.append(f\"source ({url}): {content}\")\n",
    "#     formatted_response = \"\\n--\\n\".join(cleaned_result)\n",
    "    return {\"context\": cleaned_result,\n",
    "           \"iterations\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95a92d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dafa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e09d399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78a0324",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ff3e51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e7b305",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "3d9e083a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writer_node(state: AgentState):\n",
    "    context = \"\\n---\\n\".join(state['context'])\n",
    "    topic = state['topic']\n",
    "    response = llm.invoke(f\"Please provide a concise summary about {topic} using this info: {context}\")\n",
    "    return {'summary': response.content}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "badb30e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reviewer_node(state: AgentState):\n",
    "    \"\"\"Critiques the summary for gaps or errors.\"\"\"\n",
    "    prompt = f\"Critique this summary about {state['topic']}:\\n{state['summary']}\\n. If it's perfect, output only 'PASS'. Otherwise, explain what is missing.\"\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"critique\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7479706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "96d4dde9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "1c0e9d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state: AgentState):\n",
    "    if state[\"iterations\"] > 2 or \"PASS\" == state[\"critique\"]:\n",
    "        return \"end\"\n",
    "    return \"continue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "1230e388",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"query_gen\",generate_queries_node)\n",
    "workflow.add_node(\"researcher\", research_node)\n",
    "workflow.add_node(\"writer\", writer_node)\n",
    "workflow.add_node(\"reviewer\",reviewer_node)\n",
    "\n",
    "workflow.add_edge(START,\"query_gen\")\n",
    "workflow.add_edge(\"query_gen\",\"researcher\")\n",
    "workflow.add_edge(\"researcher\",\"writer\")\n",
    "workflow.add_edge(\"writer\",\"reviewer\")\n",
    "\n",
    "workflow.add_conditional_edges(\"reviewer\",should_continue,{\n",
    "    \"continue\": \"researcher\",\n",
    "    \"end\": END\n",
    "})\n",
    "\n",
    "# ... add edges and compile\n",
    "app1 = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7665e9f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "e83e844a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'future of openai',\n",
       " 'search_queries': ['OpenAI future AI models and capabilities',\n",
       "  'OpenAI long-term business strategy and market position',\n",
       "  'OpenAI vision for artificial general intelligence and societal impact'],\n",
       " 'context': ['source (https://www.scworld.com/news/openai-outlines-plans-to-prepare-for-future-ai-cybersecurity-capabilities): OpenAI has released plans for a future of AI models with advanced cybersecurity capabilities, outlining plans to prevent misuse and empower',\n",
       "  'source (https://openai.com/open-models/): * ChatGPT(opens in a new window). * Sora(opens in a new window). # Open models by OpenAI. Advanced open-weight reasoning models to customize for any use case and run anywhere. Download on Hugging Face(opens in a new window)View on GitHub(opens in a new window)Try our models(opens in a new window). ### gpt-oss. Open reasoning models designed to run locally on desktops, laptops, and in data centers—available in 120B and 20B parameters. (opens in a new window)-0.50. Open safety reasoning models that support custom safety policies—available in 120B and 20B parameters. (opens in a new window). Try it now(opens in a new window). ## Advancing safety standards for open models. #### Safety is foundational to our open models. We’re working with leading deployment and hardware companies to offer these models to the open-source community. Share feedback and feature requests that may guide future open models. Download on Hugging Face(opens in a new window)View on GitHub(opens in a new window).',\n",
       "  'source (https://itbrief.co.nz/story/altman-sets-out-openai-roadmap-for-future-ai-co-workers): Sam Altman says AI co-workers will reshape software jobs, cut team sizes and force firms to compete on ideas, attention and resilience.',\n",
       "  'source (https://cryptorank.io/news/feed/c1c82-openai-enterprise-strategy-2026-comeback): # OpenAI Enterprise Strategy: Bold Leadership Shakeup Targets 2026 Business Market Comeback. OpenAI Enterprise Strategy: Bold Leadership Shakeup Targets 2026 Business Market Comeback. These trends collectively influence how AI companies approach the enterprise market strategically. As the enterprise AI market continues evolving, OpenAI’s 2026 performance will likely determine its long-term position in the business technology landscape. **Q2:** How has OpenAI’s enterprise market share changed recently? This post OpenAI Enterprise Strategy: Bold Leadership Shakeup Targets 2026 Business Market Comeback first appeared on BitcoinWorld. # OpenAI Enterprise Strategy: Bold Leadership Shakeup Targets 2026 Business Market Comeback. OpenAI Enterprise Strategy: Bold Leadership Shakeup Targets 2026 Business Market Comeback. These trends collectively influence how AI companies approach the enterprise market strategically. As the enterprise AI market continues evolving, OpenAI’s 2026 performance will likely determine its long-term position in the business technology landscape. **Q2:** How has OpenAI’s enterprise market share changed recently? This post OpenAI Enterprise Strategy: Bold Leadership Shakeup Targets 2026 Business Market Comeback first appeared on BitcoinWorld.',\n",
       "  \"source (https://nextword.substack.com/p/openai-enterprise-ai-strategy-2026): # Reverse Engineering OpenAI's Enterprise AI Strategy (2026). It started with OpenAI launching a post-sales / consulting arm, partnering with PE firms to sell AI transformation, and poaching Denise Dresser (former Slack CEO) as the new CRO to focus on enterprise. Then a few days ago, Sarah Friar - OpenAI’s CFO - published a blog post titled “A business that scales with the value of intelligence” that reads like an investor update, but is actually a sneak peak at OpenAI’s revenue model for years to come. In particular, she suggests that OpenAI’s revenue model will increasingly move **from selling tokens through APIs**, toward **outcome-based arrangements** where OpenAI shares revenue with its customers. This necessitated a new engagement / business model, where OpenAI (or Anthropic) gets an **explicit** **cut** of the value for every dollar that **every agentic application** earns. * OpenAI’s new engagement model with enterprise customers, which will maximize take rates and minimizes model provider churn.\",\n",
       "  'source (https://openai.com/index/a-business-that-scales-with-the-value-of-intelligence/): [Skip to main content](https://openai.com/index/a-business-that-scales-with-the-value-of-intelligence/#main). *   [API Platform(opens in a new window)](https://platform.openai.com/). *   [Research](https://openai.com/research/index/). *   [For Business](https://openai.com/business/). *   [For Developers](https://openai.com/api/). *   [Sora](https://openai.com/sora/). *   [Company](https://openai.com/about/). *   [Research Index](https://openai.com/research/index/). *   [Research Overview](https://openai.com/research/). *   [Research Residency](https://openai.com/residency/). *   [Sora 2](https://openai.com/index/sora-2/). *   [Business Overview](https://openai.com/business/). *   [Learn](https://openai.com/business/learn/). *   [ChatGPT Pricing](https://openai.com/business/chatgpt-pricing/). *   [API Pricing](https://openai.com/api/pricing/). *   [API Platform](https://openai.com/api/). *   [Agents](https://openai.com/agent-platform/). *   [Open Models](https://openai.com/open-models/). *   [Sora](https://openai.com/sora/). *   [About Us](https://openai.com/about/). As ChatGPT became a tool people rely on every day to get real work done, we followed a simple and enduring principle: our business model should scale with the value intelligence delivers. *   [ChatGPT](https://openai.com/news/?tags=chatgpt). *   [2026](https://openai.com/news/?tags=2026). [View all](https://openai.com/news/company/). [Our approach to advertising and expanding access to ChatGPT Company Jan 16, 2026](https://openai.com/index/our-approach-to-advertising-and-expanding-access/). *   [Research Index](https://openai.com/research/index/). *   [Research Overview](https://openai.com/research/). *   [Research Residency](https://openai.com/residency/). *   [GPT-4o mini](https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/). *   [Pricing](https://openai.com/sora/#pricing). *   [Platform Overview](https://openai.com/api/). *   [Pricing](https://openai.com/api/pricing/). *   [API log in(opens in a new window)](https://platform.openai.com/login). *   [Documentation(opens in a new window)](https://platform.openai.com/docs/overview). *   [Business Overview](https://openai.com/business/). *   [About Us](https://openai.com/about/). *   [Help Center(opens in a new window)](https://help.openai.com/). *   [News](https://openai.com/news/). *   [Livestreams](https://openai.com/live/).',\n",
       "  'source (https://casmi.northwestern.edu/news/articles/2024/openais-quest-for-artificial-general-intelligence-vision-or-mirage.html): Ultimately, the quest for AGI should not just be about reaching predefined levels but about fostering collaboration between humans and machines.',\n",
       "  'source (https://www.campaignasia.com/article/why-openai-believes-artificial-general-intelligence-can-align-with-humanity/495816): She explained that OpenAI is driven by a grand vision to enhance global living standards, enabling most people to access free, high-quality',\n",
       "  'source (https://openai.com/about/): OpenAI is an AI research and deployment company. Our mission is to ensure that artificial general intelligence benefits all of humanity.'],\n",
       " 'summary': \"OpenAI's future is centered on achieving Artificial General Intelligence (AGI) that benefits all humanity, enhancing global living standards through human-machine collaboration. This involves developing advanced, safe, and open-weight AI models (like ChatGPT, Sora, and gpt-oss) with integrated cybersecurity capabilities to prevent misuse, enabling customization and local deployment.\\n\\nThe company anticipates AI co-workers will reshape software jobs and team structures. Strategically, OpenAI is targeting a 2026 enterprise market comeback, shifting its revenue model from selling API tokens to outcome-based arrangements and revenue sharing from agentic applications, supported by new leadership and consulting partnerships to maximize value and minimize churn.\",\n",
       " 'critique': 'The summary is good, but it has a significant inaccuracy and misses a few key strategic elements.\\n\\nHere\\'s what\\'s missing/inaccurate:\\n\\n1.  **Inaccuracy regarding \"open-weight AI models\":** The summary states \"developing advanced, safe, and open-weight AI models (like ChatGPT, Sora, and gpt-oss)\". While \"gpt-oss\" implies a future open-source/open-weight model, **ChatGPT and Sora are definitively not open-weight models.** They are proprietary, closed-source models. This is a crucial distinction in the AI landscape, and misrepresenting OpenAI\\'s current flagship models as open-weight is incorrect. OpenAI\\'s strategy has largely been to keep its most advanced models closed-source while sometimes releasing smaller, less capable models or research findings.\\n\\n2.  **Missing emphasis on AI Safety, Alignment, and Governance:** While \"safe\" and \"integrated cybersecurity\" are mentioned, the summary doesn\\'t fully capture the extensive and often controversial focus OpenAI places on **AI alignment, superintelligence safety, and the broader governance challenges of AGI.** This includes their \"Superalignment\" team, their discussions around democratic governance of AI, and their recent formation of a new safety committee. This is a much broader and deeper commitment than just \"integrated cybersecurity capabilities.\"\\n\\n3.  **Missing the critical role of Compute/Hardware:** Achieving AGI and deploying advanced models requires immense computational resources. The summary doesn\\'t mention OpenAI\\'s strategic reliance on and investment in **massive compute infrastructure**, including its partnership with Microsoft for Azure AI supercomputers, and potential future ventures into custom AI chips. This is a foundational element for their future.\\n\\n4.  **Missing the \"Independent\" aspect of AGI development:** OpenAI often frames its AGI pursuit as being for \"all humanity\" and emphasizes a structure that aims to prevent any single entity from controlling AGI. While \"benefits all humanity\" is there, the specific organizational structure (e.g., the non-profit parent, the capped-profit subsidiary, the recent board changes) and the stated goal of ensuring AGI is developed and deployed responsibly, potentially with independent oversight, is a significant part of their future narrative.',\n",
       " 'iterations': 3}"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app1.invoke({\n",
    "    \"topic\": \"future of openai\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7d0399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3931e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
